{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross-Validation\n",
    "\n",
    "É uma técnica de reamostragem usada para avaliar a performance de um modelo de ML, usando uma quantidade de dados limitada.\n",
    "\n",
    "O procedimento tem um único parâmetro chamado **K** que se refere ao número de conjuntos em que o dataset será dividido.\n",
    "\n",
    "Portando, se k=10, teremos um 10-fold cross-validation.\n",
    "\n",
    "Cross-validation é usado principalmente em ML aplicado, onde se tenta estimar a habilidade do modelo de classificar dados ainda não vistos, ou seja, sua capacidade de generalização.\n",
    "\n",
    "Essa técnica é popular pois é símples de entender e aplicar, além disso, a mesma ajuda a diminuir o viés melhor que outras técnicas como o simples divisão do dataset em treino/test. \n",
    "\n",
    "Os passos para aplicar esse procedimento são:\n",
    "\n",
    "1. \"Embaralhe\" as observações do dataset de forma aleatória;\n",
    "2. Divida o dataset em k conjuntos;\n",
    "3. Para cada conjunto:\n",
    "    1. Reserve o conjunto em questão para teste;\n",
    "    2. Use os conjuntos restantes como dataset de treino;\n",
    "    3. Treine o o modelo do dataset de treino e avalie o mesmo no dataset de teste;\n",
    "    4. Retenha a métrica de avaliação e discarte o modelo.\n",
    "4. Resuma as skills do modelo usando a amostra das métricas de avaliação dos modelos que foram gerados.\n",
    "\n",
    "Os resultados de uma execução de validação cruzada k-fold são frequentemente resumidos com a média das métricas de avaliação. Também é uma boa prática incluir a medida da variação e do desvio padrão ou o erro padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como escolher **K**\n",
    "\n",
    "K deve ser escolhido de forma cuidadosa, baseado nos dados que você possue. \n",
    "\n",
    "A escolha de um K errado,  pode resultar numa ideia da performance do modelo bem afastada da realidade.\n",
    "\n",
    "As três táticas mais comuns para escolher o valor de k são:\n",
    "\n",
    "* **Representativo**: O valor de k é escolhido de modo que cada grupo de treino/teste de amostras dos dados seja grande o suficiente para ser estatisticamente representativo no dataset como um todo.\n",
    "\n",
    "* **k=10**: esse valor foi encontrado através de experimentação, geralmente resulta em uma estimativa da performance do modelo com baixo viés e variação modesta.\n",
    "\n",
    "* **k=n**: O valor de k é fixo em n, em que n é o tamanho do conjunto de dados para dar a cada amostra de teste a oportunidade de ser usada como teste. Essa abordagem é chamada de validação cruzada de exclusão única (leave-one-out cross-validation).\n",
    "\n",
    "Ná dúvida, escolha algo entre e 5-10 para k.\n",
    "\n",
    "*\"The choice of k is usually 5 or 10, but there is no formal rule. As k gets larger, the difference in size between the training set and the resampling subsets gets smaller. As this difference decreases, the bias of the technique becomes smaller\"* p.g 70, [Applied Predictive Modeling](https://github.com/mravendi/data-science-machine-learning-ai-resources/blob/master/books/Applied%20Predictive%20Modeling.pdf)\n",
    "\n",
    "*\"To summarize, there is a bias-variance trade-off associated with the choice of k in k-fold cross-validation. Typically, given these considerations, one performs k-fold cross-validation using k = 5 or k = 10, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance.\"* pg. 184, [An Introduction to Statistical Learning](https://github.com/tpn/pdfs/blob/master/An%20Introduction%20To%20Statistical%20Learning%20with%20Applications%20in%20R%20(ISLR%20Sixth%20Printing).pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de Cross-Validation\n",
    "\n",
    "* **Divisão Treino/Teste**: é uma forma de k-folders com k=2.\n",
    "* **LOOCV**: abreviação para leave-one-out cross-validation. Também é um tipo de k-folders só que com levado ao máximo, ou seja, k é fixo em *n*, em que *n* é o tamanho do conjunto de dados para dar a cada amostra de teste a oportunidade de ser usada como teste.\n",
    "* **Estratificado**: cada fold deve conter uma amostra representativa de cada classe existente do datset. Por exemplo, em um problema de classificação binária em que cada classe compreende 50% dos dados, é melhor organizar os dados de modo que, metade dos dados, dentro de cada fold, pertença a classe A e a outra metade pertencente a classe B.\n",
    "* **Repetido**: o k-folders é repetido *n* vezes, antes de cada repetição, o dataset é embaralhado.\n",
    "\n",
    "Para ver a lista de implementações de diferentes cross-validation do scikit-learning, clique [aqui](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando scikit-learn para gerar o k-folders\n",
    "\n",
    "Com seguinte instância da classe KFold do sciki-learning, teremos um dataset dividido em 3 partes, e \"embaralha\" de forma aleatória o dataset com a semente aleatória 1.\n",
    "\n",
    "```python\n",
    "kfold = KFold(3, True, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.1 0.4 0.5 0.6], test: [0.2 0.3]\n",
      "train: [0.2 0.3 0.4 0.6], test: [0.1 0.5]\n",
      "train: [0.1 0.2 0.3 0.5], test: [0.4 0.6]\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn k-fold cross-validation\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "# dataset\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "# preparando cross validation\n",
    "kfold = KFold(3, True, 1)\n",
    "\n",
    "for train, test in kfold.split(data):\n",
    "\tprint('train: %s, test: %s' % (data[train], data[test]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
